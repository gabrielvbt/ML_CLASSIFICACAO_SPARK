{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA TRABALHAR COM O GOOGLE COLAB É NECESSÁRIO:\n",
    "# !apt-get update -qq\n",
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
    "# !pip install -q findspark\n",
    "\n",
    "import os\n",
    "import findspark\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"D:/spark-3.5.5-bin-hadoop3\"\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import DoubleType, StringType\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obs: para este projeto estamos trabalhando com o google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "DADOS = spark.read.csv('/content/drive/ml/dados_clientes.csv', sep=',', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJETO DE CLASSIFICAÇÃO DE CLIENTES (POSSIVEIS CANCELAMENTO DE CONTAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TROCANDO COLUNAS COM SIM/NAO PARA 1/0\n",
    "VARIAVEIS_STRING = ['Churn', 'Conjuge', 'Dependentes', 'TelefonixeFixo','MaisDeUmaLinhaTelefonica']\n",
    "\n",
    "QUERY = [f.when(f.col(c) == 'Sim', 1).otherwise(0).alias(c) for c in VARIAVEIS_STRING]\n",
    "# reversed abaixo apenas inverte a ordem das colunas, a ultima vira primeira e assim por diante\n",
    "for coluna in reversed(DADOS.columns):\n",
    "    if coluna not in VARIAVEIS_STRING:\n",
    "        QUERY.insert(0, coluna)\n",
    "\n",
    "SPARK = DADOS.select(QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMAR COLUNAS MULTICATEGORICAS STRING PARA BINÁRIOS COM PIVOT (DUMMIES)\n",
    "DUMMIES_1 = SPARK.groupBy('id'.pivot('Internet')).agg.(f.lit(1)).na.fill(0)\n",
    "DUMMIES_2 = SPARK.groupBy('id'.pivot('TipoContrato')).agg.(f.lit(1)).na.fill(0)\n",
    "DUMMIES_3 = SPARK.groupBy('id'.pivot('MetodoPagamento')).agg.(f.lit(1)).na.fill(0)\n",
    "\n",
    "SPARK = SPARK\\\n",
    "            .join(DUMMIES_1, 'id', how='inner')\\\n",
    "            .join(DUMMIES_2, 'id', how='inner')\\\n",
    "            .join(DUMMIES_3, 'id', how='inner')\\\n",
    "            .select('*', f.col('DSL').alias('Internet_DSL'),\n",
    "                        f.col('FibraOptica').alias('Internet_FibraOptica'), \n",
    "                        f.col('Nao').alias('Internet_Nao'), \n",
    "                        f.col('Mensalmente').alias('TipoContrato_Mensalmente'), \n",
    "                        f.col('UmAno').alias('TipoContrato_UmAno'), \n",
    "                        f.col('DoisAnos').alias('TipoContrato_DoisAnos'), \n",
    "                        f.col('DebitoEmConta').alias('MetodoPagamento_DebitoEmConta'), \n",
    "                        f.col('CartaoCredito').alias('MetodoPagamento_CartaoCredito'), \n",
    "                        f.col('BoletoEletronico').alias('MetodoPagamento_BoletoEletronico'), \n",
    "                        f.col('Boleto').alias('MetodoPagamento_Boleto')  \n",
    "            )\\\n",
    "            .drop('Internet', 'TipoContrato', 'MetodoPagamento', 'DSL', \n",
    "                'FibraOptica', 'Nao', 'Mensalmente', 'UmAno', 'DoisAnos', \n",
    "                'DebitoEmConta', 'CartaoCredito', 'BoletoEletronico', 'Boleto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VETORIZANDO AS COLUNAS PARA QUE AS LIBS DE ML POSSAM TRABALHAR\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "SPARK = SPARK.withColumnRenamed('Churn', 'label')\n",
    "\n",
    "X = SPARK.columns\n",
    "X.remove('label')\n",
    "X.remove('id')\n",
    "\n",
    "# A VETORIZAÇÃO É FEITA PELO OBJETO VETOR E AS FUNÇÕES DO SPARK ESPERAM RECEBER O OUTPUT COM NOME 'features'\n",
    "ASSEMBLER = VectorAssembler(inputCols=X, outputCol='features')\n",
    "\n",
    "DF_PREP = ASSEMBLER.transform(SPARK).select('features', 'label')\n",
    "\n",
    "TREINO, TESTE = DF_PREP.randomSplit([0.7, 0.3], seed=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSÃO LOGISTICA (LOGISTIC REGRESSION)\n",
    "### A principal diferença entre a regressão logistica e a linear é que ao final da execução do processo a regressão logistica aplica uma função chamada \"Sigmoide\" que transforma o resultado em valores entre 0 e 1, assim, separando em classes, multivaloradas, com base em uma porcentagem para cada valor da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "MODELO_LR = LR.fit(TREINO)\n",
    "\n",
    "PREVISOES_LR_TESTE = MODELO_LR.transform(TREINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MÉTRICAS ##########\n",
    "\n",
    "RESUMO = MODELO_LR.summary\n",
    "\n",
    "print(\"Acurácia: %f\" % RESUMO.accuracy)\n",
    "print(\"Precisão: %f\" % RESUMO.precisionByLabel[1])\n",
    "print(\"Recall: %f\" % RESUMO.recallByLabel[1])\n",
    "print(\"F1: %f\" % RESUMO.fMeasureByLabel()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARVORE DE DECISÃO PARA CLASSIFICAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "DTC = DecisionTreeClassifier(seed=101)\n",
    "\n",
    "MODELO_DTC = DTC.fit(TREINO)\n",
    "PREVISOES_DTC_TREINO = MODELO_DTC.transform(TREINO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MÉTRICAS COM FERRAMENTA NOVA ##########\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "\n",
    "print(\"Acurácia: %f\" % evaluator.evaluate(PREVISOES_DTC_TREINO, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"Precisão: %f\" % evaluator.evaluate(PREVISOES_DTC_TREINO, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"Recall: %f\" % evaluator.evaluate(PREVISOES_DTC_TREINO, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"F1: %f\" % evaluator.evaluate(PREVISOES_DTC_TREINO, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVISOES_DTC_TESTE = MODELO_DTC.transform(TESTE)\n",
    "\n",
    "print(\"Acurácia: %f\" % evaluator.evaluate(PREVISOES_DTC_TESTE, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"Precisão: %f\" % evaluator.evaluate(PREVISOES_DTC_TESTE, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"Recall: %f\" % evaluator.evaluate(PREVISOES_DTC_TESTE, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"F1: %f\" % evaluator.evaluate(PREVISOES_DTC_TESTE, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST PARA CLASSIFICACAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier(seed=101)\n",
    "\n",
    "MODELO_RFC = RFC.fit(TREINO)\n",
    "PREVISOES_RFC_TREINO = MODELO_RFC.transform(TREINO)\n",
    "PREVISOES_RFC_TESTE = MODELO_RFC.transform(TESTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## MÉTRICAS ##########\n",
    "\n",
    "print(15*'=' + ' TREINO ' + 25*'=')\n",
    "print(\"Acurácia: %f\" % evaluator.evaluate(PREVISOES_RFC_TREINO, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"Precisão: %f\" % evaluator.evaluate(PREVISOES_RFC_TREINO, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"Recall: %f\" % evaluator.evaluate(PREVISOES_RFC_TREINO, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"F1: %f\" % evaluator.evaluate(PREVISOES_RFC_TREINO, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: 1}))\n",
    "print(15*'=' + ' TESTE ' + 25*'=')\n",
    "print(\"Acurácia: %f\" % evaluator.evaluate(PREVISOES_RFC_TESTE, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"Precisão: %f\" % evaluator.evaluate(PREVISOES_RFC_TESTE, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"Recall: %f\" % evaluator.evaluate(PREVISOES_RFC_TESTE, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"F1: %f\" % evaluator.evaluate(PREVISOES_RFC_TESTE, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TÉCNICAS DE OTIMIZAÇÃO: CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA O MÉTODO DE ARVORE DE DECISÃO\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "#########################################################################\n",
    "###       O CROSS VALIDATOR NOS PERMITE FAZER DIVERSAS SEPARAÇÕES     ###\n",
    "###       DE TREINO/TESTE PARA AVALIAR/TREINAR MELHOR O MODELO        ###\n",
    "###      E O PARAMGRIDBUILDER É RESPONSAVEL NOS DEIXA AVALIAR MAIS    ###\n",
    "###    PARAMETROS DE UMA VEZ PARA ENTENDERMOS QUAL O MELHOR PARAMETRO ###\n",
    "###                         PARA OS MODELOS                           ###\n",
    "#########################################################################\n",
    "\n",
    "GRID = ParamGridBuilder().addGrid(DTC.maxDepth, [2, 5, 10]).addGrid(DTC.maxBins, [10, 32, 45]).build()\n",
    "DTR_CV = CrossValidator(estimator=DTC, estimatorParamMaps=GRID, evaluator=evaluator, numFolds=3, seed=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELO_DTC_CV = DTR_CV.fit(TREINO)\n",
    "PREVISOES_DTC_CV_TESTE = MODELO_DTC_CV.transform(TESTE)\n",
    "\n",
    "\n",
    "print(\"Acurácia: %f\" % evaluator.evaluate(PREVISOES_DTC_CV_TESTE, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"Precisão: %f\" % evaluator.evaluate(PREVISOES_DTC_CV_TESTE, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"Recall: %f\" % evaluator.evaluate(PREVISOES_DTC_CV_TESTE, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"F1: %f\" % evaluator.evaluate(PREVISOES_DTC_CV_TESTE, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARA O MÉTODO RANDOM FOREST\n",
    "\n",
    "GRID = ParamGridBuilder().addGrid(RFC.maxDepth, [2, 5, 10]).addGrid(RFC.maxBins, [10, 32, 45]).addGrid(RFC.numTrees, [10, 20, 50]).build()\n",
    "RFC_CV = CrossValidator(estimator=RFC, estimatorParamMaps=GRID, evaluator=evaluator, numFolds=3, seed=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELO_RFC_CV = DTR_CV.fit(TREINO)\n",
    "PREVISOES_RFC_CV_TESTE = MODELO_RFC_CV.transform(TESTE)\n",
    "\n",
    "\n",
    "print(\"Acurácia: %f\" % evaluator.evaluate(PREVISOES_RFC_CV_TESTE, {evaluator.metricName: \"accuracy\"}))\n",
    "print(\"Precisão: %f\" % evaluator.evaluate(PREVISOES_RFC_CV_TESTE, {evaluator.metricName: \"precisionByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"Recall: %f\" % evaluator.evaluate(PREVISOES_RFC_CV_TESTE, {evaluator.metricName: \"recallByLabel\", evaluator.metricLabel: 1}))\n",
    "print(\"F1: %f\" % evaluator.evaluate(PREVISOES_RFC_CV_TESTE, {evaluator.metricName: \"fMeasureByLabel\", evaluator.metricLabel: 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETERMINAÇÃO DO MELHOR MODELO PELAS METRICAS CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_RFC_CV = MODELO_RFC_CV.bestModel\n",
    "\n",
    "# AGORA PARA ENCONTRAR OS HIPERPARAMETROS MAIS ADEQUADOS:\n",
    "DEPTH = BEST_MODEL_RFC_CV.getMaxDepth()\n",
    "BINS = BEST_MODEL_RFC_CV.getMaxBins()\n",
    "TREES = BEST_MODEL_RFC_CV.getNumTrees()\n",
    "\n",
    "RFC_TUNING = RandomForestClassifier(maxDepth=DEPTH, maxBins=BINS, numTrees=TREES, seed=101)\n",
    "MODELO_TUNING_RFC = RFC_TUNING.fir(DF_PREP)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
